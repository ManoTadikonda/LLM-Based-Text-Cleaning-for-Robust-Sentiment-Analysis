{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sVmpKGBOsYU"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect environment\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "    # Install required libraries on Colab\n",
        "    !pip install transformers datasets torch scikit-learn matplotlib anthropic openai -q\n",
        "    print(\"All libraries installed\")\n",
        "else:\n",
        "    print(\"Running on Local Machine\")\n",
        "    print(\"Make sure you have installed: transformers datasets torch scikit-learn matplotlib anthropic openai\")\n",
        "    print(\"Install with: pip install transformers datasets torch scikit-learn matplotlib anthropic openai\")\n",
        "\n",
        "# Standard imports\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# GPU Optimization Setup\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True  # 8x speedup on A100\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"âœ“ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"âš  No GPU detected\")\n",
        "\n",
        "print(\"Environment setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyvZpOCEOw9S"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Train DistilBERT Model on Clean Data\n",
        "# OPTIMIZED FOR A100 GPU - FULL 25K TRAINING SET\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Model Training on Clean IMDB Data\")\n",
        "\n",
        "if not IS_COLAB:\n",
        "    print(\"Warning: Training on local machine may be slow without GPU\")\n",
        "    print(\"Recommended: Run this cell on Google Colab with GPU enabled\")\n",
        "    print(\"(Runtime > Change runtime type > GPU)\")\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# Load IMDB training data\n",
        "print(\"Loading IMDB training data...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Use ALL 25,000 samples for training (80/20 train/val split)\n",
        "full_train = dataset['train'].shuffle(seed=42)  # Use .select(range(10000)) if needed.\n",
        "\n",
        "train_size = int(0.8 * len(full_train))  # 20,000 for training\n",
        "val_size = len(full_train) - train_size  # 5,000 for validation\n",
        "\n",
        "train_dataset = full_train.select(range(train_size))\n",
        "val_dataset = full_train.select(range(train_size, train_size + val_size))\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "# Load tokenizer and tokenize data\n",
        "print(\"Loading DistilBERT tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "print(\"Tokenizing data (this may take a few minutes)...\")\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "print(\"Data tokenized\")\n",
        "\n",
        "# Load model\n",
        "print(\"Loading DistilBERT model...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2  # Binary classification (positive/negative)\n",
        ")\n",
        "\n",
        "# Define metrics for evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary'\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Training configuration - OPTIMIZED FOR A100 with Early Stopping\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,\n",
        "\n",
        "    # A100 GPU Settings\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=256,\n",
        "    fp16=True,\n",
        "    dataloader_num_workers=4,\n",
        "    dataloader_pin_memory=True,\n",
        "\n",
        "    # For T4 GPU, uncomment these instead:\n",
        "    # per_device_train_batch_size=16,\n",
        "    # per_device_eval_batch_size=32,\n",
        "\n",
        "    # Evaluation & Saving\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=150,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=150,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # Logging & Optimization\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "print(\"Starting training with early stopping...\")\n",
        "print(\"Training on FULL 25K dataset - up to 10 epochs\")\n",
        "print(\"Expected time: 5-10 minutes on A100 GPU\")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print(\"Training complete\")\n",
        "\n",
        "# Show final validation results\n",
        "print(\"\\nFinal Validation Results:\")\n",
        "eval_results = trainer.evaluate()\n",
        "for key, value in eval_results.items():\n",
        "    if 'eval_' in key:\n",
        "        print(f\"  {key.replace('eval_', ''):12}: {value:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "print(\"Saving model...\")\n",
        "model.save_pretrained(\"./sentiment_model\")\n",
        "tokenizer.save_pretrained(\"./sentiment_model\")\n",
        "print(\"Model saved to './sentiment_model'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONX_KERgOxAG"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Download Model (Colab)\n",
        "# Creates zip file and downloads on Colab for use in later sessions\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nSave and Download Model\")\n",
        "\n",
        "if IS_COLAB:\n",
        "    import shutil\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"Creating zip file for download...\")\n",
        "    shutil.make_archive('sentiment_model', 'zip', '.', 'sentiment_model')\n",
        "    files.download('sentiment_model.zip')\n",
        "    print(\"Model downloaded - save this file\")\n",
        "    print(\"You can upload this to run evaluation on Colab or locally\")\n",
        "else:\n",
        "    print(\"Model saved locally at './sentiment_model'\")\n",
        "    print(\"You can use this model for evaluation without retraining\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7EbE9xBOxC9"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Load Clean Test Reviews\n",
        "# Downloads IMDB test set and saves 1000 clean reviews for testing\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nLoading Clean Test Reviews\")\n",
        "\n",
        "# Load IMDB test data\n",
        "print(\"Loading IMDB dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "print(f\"Loaded {len(dataset['test'])} test reviews\")\n",
        "\n",
        "# Sample 1000 reviews for testing (change this number for experimentation)\n",
        "TEST_SIZE = 1000\n",
        "test_data = dataset['test'].shuffle(seed=42).select(range(TEST_SIZE))\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'text': test_data['text'],\n",
        "    'label': test_data['label']\n",
        "})\n",
        "\n",
        "# Save clean reviews\n",
        "df.to_csv('clean_reviews.csv', index=False)\n",
        "print(f\"Saved {len(df)} clean reviews to 'clean_reviews.csv'\")\n",
        "\n",
        "# Show first review example\n",
        "print(\"\\nExample Review (first 200 chars):\")\n",
        "print(df['text'].iloc[0][:200] + \"...\")\n",
        "\n",
        "# Download on Colab (optional on local)\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('clean_reviews.csv')\n",
        "    print(\"File downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUKE4VMSOxFj"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Noise Injection Setup and Application\n",
        "# Adds synthetic noise to test reviews to simulate real-world messy text\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nNoise Injection Setup\")\n",
        "\n",
        "# ----- CHARACTER-LEVEL NOISE FUNCTIONS -----\n",
        "\n",
        "def add_typos(text):\n",
        "    \"\"\"Swap adjacent letters in 20% of words (simulate typing errors)\"\"\"\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) > 3 and random.random() < 0.2:\n",
        "            idx = random.randint(0, len(word)-2)\n",
        "            word_list = list(word)\n",
        "            word_list[idx], word_list[idx+1] = word_list[idx+1], word_list[idx]\n",
        "            word = ''.join(word_list)\n",
        "        noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "def elongate_words(text):\n",
        "    \"\"\"Elongate vowels in 15% of words (e.g., 'good' -> 'goood')\"\"\"\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) > 3 and random.random() < 0.15:\n",
        "            for i, char in enumerate(word):\n",
        "                if char in 'aeiouAEIOU':\n",
        "                    word = word[:i] + char*3 + word[i+1:]\n",
        "                    break\n",
        "        noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "def add_keyboard_typos(text):\n",
        "    \"\"\"Simulate adjacent key presses on QWERTY keyboard\"\"\"\n",
        "    keyboard_neighbors = {\n",
        "        'a': 'sqwz', 'b': 'vghn', 'c': 'xdfv', 'd': 'sfcxe', 'e': 'rdsw',\n",
        "        'f': 'dgcvr', 'g': 'fhtbv', 'h': 'gjnby', 'i': 'oukj', 'j': 'hknui',\n",
        "        'k': 'jlmio', 'l': 'kop', 'm': 'njk', 'n': 'bhjm', 'o': 'ipkl',\n",
        "        'p': 'ol', 'q': 'wa', 'r': 'tfde', 's': 'awedxz', 't': 'rgfy',\n",
        "        'u': 'yihj', 'v': 'cfgb', 'w': 'qase', 'x': 'zsdc', 'y': 'tugh',\n",
        "        'z': 'asx'\n",
        "    }\n",
        "\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) > 3 and random.random() < 0.1:\n",
        "            idx = random.randint(0, len(word)-1)\n",
        "            char = word[idx].lower()\n",
        "            if char in keyboard_neighbors:\n",
        "                new_char = random.choice(keyboard_neighbors[char])\n",
        "                word = word[:idx] + new_char + word[idx+1:]\n",
        "        noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "def delete_chars(text):\n",
        "    \"\"\"Randomly delete characters from 10% of words\"\"\"\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) > 4 and random.random() < 0.1:\n",
        "            idx = random.randint(1, len(word)-2)\n",
        "            word = word[:idx] + word[idx+1:]\n",
        "        noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "def insert_chars(text):\n",
        "    \"\"\"Randomly insert characters into 10% of words\"\"\"\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) > 3 and random.random() < 0.1:\n",
        "            idx = random.randint(1, len(word)-1)\n",
        "            char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "            word = word[:idx] + char + word[idx:]\n",
        "        noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "def add_random_caps(text):\n",
        "    \"\"\"Randomly capitalize letters (e.g., 'movie' -> 'mOvIe')\"\"\"\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(word) > 3 and random.random() < 0.15:\n",
        "            word = ''.join([c.upper() if random.random() < 0.3 else c for c in word])\n",
        "        noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "# ----- WORD-LEVEL NOISE FUNCTIONS -----\n",
        "\n",
        "def add_slang(text):\n",
        "    \"\"\"Replace common words with internet slang\"\"\"\n",
        "    slang_map = {\n",
        "        # Intensifiers\n",
        "        ' really ': ' fr fr ',\n",
        "        ' very ': ' hella ',\n",
        "        ' so ': ' lowkey ',\n",
        "        ' extremely ': ' deadass ',\n",
        "        ' absolutely ': ' facts ',\n",
        "        ' totally ': ' legit ',\n",
        "        ' quite ': ' kinda ',\n",
        "\n",
        "        # Positive words\n",
        "        ' good ': ' fire ',\n",
        "        ' great ': ' goated ',\n",
        "        ' awesome ': ' bussin ',\n",
        "        ' amazing ': ' slaps ',\n",
        "        ' excellent ': ' valid ',\n",
        "        ' wonderful ': ' hits different ',\n",
        "        ' fantastic ': ' no cap ',\n",
        "        ' perfect ': ' chef kiss ',\n",
        "        ' beautiful ': ' aesthetic ',\n",
        "        ' cool ': ' dope ',\n",
        "        ' fun ': ' lit ',\n",
        "        ' funny ': ' hilarious ngl ',\n",
        "        ' interesting ': ' lowkey interesting ',\n",
        "\n",
        "        # Negative words\n",
        "        ' bad ': ' trash ',\n",
        "        ' terrible ': ' ass ',\n",
        "        ' awful ': ' mid ',\n",
        "        ' horrible ': ' straight garbage ',\n",
        "        ' boring ': ' mid af ',\n",
        "        ' stupid ': ' dumb af ',\n",
        "        ' annoying ': ' cringe ',\n",
        "        ' disappointing ': ' L ',\n",
        "        ' worst ': ' trash tier ',\n",
        "        ' weak ': ' weak sauce ',\n",
        "\n",
        "        # Emotions\n",
        "        ' love ': ' stan ',\n",
        "        ' like ': ' fw ',\n",
        "        ' hate ': ' can\\'t stand ',\n",
        "        ' enjoy ': ' vibe with ',\n",
        "        ' sad ': ' dead inside ',\n",
        "        ' happy ': ' vibing ',\n",
        "        ' angry ': ' tilted ',\n",
        "        ' scared ': ' shook ',\n",
        "        ' excited ': ' hyped ',\n",
        "\n",
        "        # Other common words\n",
        "        ' thing ': ' joint ',\n",
        "        ' person ': ' dude ',\n",
        "        ' people ': ' folks ',\n",
        "        ' money ': ' bread ',\n",
        "        ' understand ': ' get ',\n",
        "        ' believe ': ' buy ',\n",
        "        ' watch ': ' peep ',\n",
        "        ' look ': ' peep ',\n",
        "        ' think ': ' reckon ',\n",
        "    }\n",
        "\n",
        "    for word, slang in slang_map.items():\n",
        "        text = text.replace(word, slang)\n",
        "\n",
        "    return text\n",
        "\n",
        "def add_word_dropout(text):\n",
        "    \"\"\"Randomly remove 5% of words\"\"\"\n",
        "    words = text.split()\n",
        "    filtered_words = [w for w in words if random.random() > 0.05]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def add_word_repeat(text):\n",
        "    \"\"\"Randomly repeat 5% of words\"\"\"\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        noisy_words.append(word)\n",
        "        if random.random() < 0.05:\n",
        "            noisy_words.append(word)\n",
        "\n",
        "    return ' '.join(noisy_words)\n",
        "\n",
        "def add_word_swap(text):\n",
        "    \"\"\"Randomly swap adjacent words\"\"\"\n",
        "    words = text.split()\n",
        "    if len(words) < 2:\n",
        "        return text\n",
        "\n",
        "    i = 0\n",
        "    while i < len(words) - 1:\n",
        "        if random.random() < 0.05:\n",
        "            words[i], words[i+1] = words[i+1], words[i]\n",
        "            i += 2\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# ----- OTHER NOISE FUNCTIONS -----\n",
        "\n",
        "def add_emojis(text):\n",
        "    \"\"\"Add random emojis to end of text\"\"\"\n",
        "    emojis = ['ðŸ˜­', 'ðŸ”¥', 'ðŸ’€', 'ðŸ˜‚', 'ðŸ’˜', 'ðŸ˜©', 'ðŸ’¯', 'ðŸ˜']\n",
        "    num_emojis = random.randint(1, 3)\n",
        "    for _ in range(num_emojis):\n",
        "        text += ' ' + random.choice(emojis)\n",
        "    return text\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"Remove all punctuation marks\"\"\"\n",
        "    import string\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "\n",
        "# ----- NOISE CONFIGURATION -----\n",
        "# Enable/disable noise types for easy experimentation\n",
        "# Set to True to enable, False to disable\n",
        "\n",
        "NOISE_CONFIG = {\n",
        "    # Character-level noise (realistic moderate noise)\n",
        "    'typos': True,              # Swap adjacent letters - common typing errors\n",
        "    'elongation': True,         # Repeat vowels (goood) - common in social media\n",
        "    'keyboard_typos': True,     # Adjacent key mistakes - realistic typos\n",
        "    'delete_chars': False,      # Remove random characters - too aggressive\n",
        "    'insert_chars': False,      # Add random characters - too aggressive\n",
        "    'random_caps': True,        # Mix upper/lowercase - common in informal text\n",
        "\n",
        "    # Word-level noise (realistic social media style)\n",
        "    'slang': True,              # Replace with internet slang - very common\n",
        "    'word_dropout': True,       # Remove random words - happens in quick typing\n",
        "    'word_repeat': False,       # Duplicate words - less common\n",
        "    'word_swap': False,         # Swap adjacent words - less common\n",
        "\n",
        "    # Other noise\n",
        "    'emojis': False,            # Add emojis (disable per professor request)\n",
        "    'remove_punctuation': False # Strip punctuation - too aggressive\n",
        "}\n",
        "\n",
        "def add_all_noise(text):\n",
        "    \"\"\"Apply all enabled noise types based on NOISE_CONFIG\"\"\"\n",
        "    # Character-level noise\n",
        "    if NOISE_CONFIG['typos']:\n",
        "        text = add_typos(text)\n",
        "    if NOISE_CONFIG['elongation']:\n",
        "        text = elongate_words(text)\n",
        "    if NOISE_CONFIG['keyboard_typos']:\n",
        "        text = add_keyboard_typos(text)\n",
        "    if NOISE_CONFIG['delete_chars']:\n",
        "        text = delete_chars(text)\n",
        "    if NOISE_CONFIG['insert_chars']:\n",
        "        text = insert_chars(text)\n",
        "    if NOISE_CONFIG['random_caps']:\n",
        "        text = add_random_caps(text)\n",
        "\n",
        "    # Word-level noise\n",
        "    if NOISE_CONFIG['slang']:\n",
        "        text = add_slang(text)\n",
        "    if NOISE_CONFIG['word_dropout']:\n",
        "        text = add_word_dropout(text)\n",
        "    if NOISE_CONFIG['word_repeat']:\n",
        "        text = add_word_repeat(text)\n",
        "    if NOISE_CONFIG['word_swap']:\n",
        "        text = add_word_swap(text)\n",
        "\n",
        "    # Other noise\n",
        "    if NOISE_CONFIG['emojis']:\n",
        "        text = add_emojis(text)\n",
        "    if NOISE_CONFIG['remove_punctuation']:\n",
        "        text = remove_punctuation(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Display active noise types\n",
        "print(\"Active noise types:\")\n",
        "for noise_type, enabled in NOISE_CONFIG.items():\n",
        "    if enabled:\n",
        "        print(f\"  - {noise_type}\")\n",
        "\n",
        "print(\"Noise functions ready\")\n",
        "\n",
        "# Apply noise to test reviews\n",
        "print(\"\\nApplying Noise to Test Reviews\")\n",
        "\n",
        "# Load clean reviews\n",
        "df = pd.read_csv('clean_reviews.csv')\n",
        "\n",
        "# Add noise to each review\n",
        "print(f\"Adding noise to {len(df)} reviews...\")\n",
        "df['noisy_text'] = df['text'].apply(add_all_noise)\n",
        "\n",
        "# Save noisy reviews\n",
        "df.to_csv('noisy_reviews.csv', index=False)\n",
        "print(\"Saved noisy reviews to 'noisy_reviews.csv'\")\n",
        "\n",
        "# Show examples of clean vs noisy\n",
        "print(\"\\nClean vs Noisy Examples:\")\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"CLEAN: {df['text'].iloc[i][:150]}...\")\n",
        "    print(f\"NOISY: {df['noisy_text'].iloc[i][:150]}...\")\n",
        "\n",
        "# Download on Colab (optional on local)\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('noisy_reviews.csv')\n",
        "    print(\"File downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQjC0-_iOxIK"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# LLM-Based Cleaning Configuration\n",
        "# Setup for cleaning noisy text using BOTH Claude AND GPT for comparison\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nLLM Cleaning Setup\")\n",
        "\n",
        "# API Keys - REPLACE WITH YOUR OWN KEYS\n",
        "# CLAUDE_API_KEY = \"your-claude-api-key-here\"\n",
        "# OPENAI_API_KEY = \"your-openai-api-key-here\"\n",
        "\n",
        "# ----- LLM CLEANING FUNCTIONS -----\n",
        "\n",
        "def clean_with_claude(text):\n",
        "    \"\"\"Clean noisy text using Claude Haiku (fast and cheap)\"\"\"\n",
        "    import anthropic\n",
        "    client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
        "\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-haiku-4-5-20251001\",  # Fast model for cleaning\n",
        "        max_tokens=1024,\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Rewrite this movie review in standard English. Fix all typos, replace slang with proper words, fix elongated words, fix capitalization. Keep the exact same sentiment (positive/negative). Only return the cleaned review:\\n\\n{text}\"\n",
        "        }]\n",
        "    )\n",
        "    return message.content[0].text.strip()\n",
        "\n",
        "def clean_with_openai(text):\n",
        "    \"\"\"Clean noisy text using OpenAI GPT\"\"\"\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        max_tokens=1024,\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Rewrite this movie review in standard English. Fix all typos, replace slang with proper words, fix elongated words, fix capitalization. Keep the exact same sentiment (positive/negative). Only return the cleaned review:\\n\\n{text}\"\n",
        "        }]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "print(\"Note: Cleaning with BOTH LLMs will take 60-120 minutes for 1000 reviews\")\n",
        "print(\"Cost: Approximately $10-20 total for both providers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23k_DMGvOxKx"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Clean Noisy Reviews with Claude\n",
        "# Processes all noisy reviews through Claude Haiku\n",
        "# Includes retry logic and progress saving\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nClaude Cleaning Process\")\n",
        "\n",
        "# Load noisy reviews\n",
        "df = pd.read_csv('noisy_reviews.csv')\n",
        "\n",
        "# Check if we're resuming from a previous run\n",
        "if 'claude_cleaned' in df.columns:\n",
        "    claude_cleaned_reviews = df['claude_cleaned'].tolist()\n",
        "    # Find where we left off\n",
        "    start_from = 0\n",
        "    for idx, val in enumerate(claude_cleaned_reviews):\n",
        "        if val == '' or pd.isna(val):\n",
        "            start_from = idx\n",
        "            break\n",
        "        start_from = idx + 1\n",
        "    print(f\"Resuming Claude cleaning from review {start_from}\")\n",
        "else:\n",
        "    claude_cleaned_reviews = [''] * len(df)\n",
        "    start_from = 0\n",
        "    print(f\"Starting Claude cleaning from review 0\")\n",
        "\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "print(f\"Remaining: {len(df) - start_from}\")\n",
        "\n",
        "# Clean each review with Claude\n",
        "for i in range(start_from, len(df)):\n",
        "    noisy_text = df['noisy_text'].iloc[i]\n",
        "\n",
        "    # Progress update every 25 reviews\n",
        "    if i % 25 == 0:\n",
        "        print(f\"Claude progress: {i}/{len(df)} reviews cleaned...\")\n",
        "\n",
        "    # Retry mechanism for API errors\n",
        "    retry_count = 0\n",
        "    max_retries = 3\n",
        "\n",
        "    while retry_count < max_retries:\n",
        "        try:\n",
        "            cleaned = clean_with_claude(noisy_text)\n",
        "            claude_cleaned_reviews[i] = cleaned\n",
        "            break  # Success, move to next review\n",
        "\n",
        "        except Exception as e:\n",
        "            error_str = str(e).lower()\n",
        "\n",
        "            # Check for rate limit / overload errors\n",
        "            if \"overloaded\" in error_str or \"529\" in error_str or \"rate\" in error_str:\n",
        "                retry_count += 1\n",
        "                if retry_count < max_retries:\n",
        "                    print(f\"  Claude API busy at review {i}, waiting 10 seconds... (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(10)\n",
        "                else:\n",
        "                    print(f\"  Skipping review {i} after {max_retries} retries\")\n",
        "                    claude_cleaned_reviews[i] = noisy_text  # Keep noisy if all retries fail\n",
        "            else:\n",
        "                # Other errors - don't retry\n",
        "                print(f\"  Error at review {i}: {e}\")\n",
        "                claude_cleaned_reviews[i] = noisy_text\n",
        "                break\n",
        "\n",
        "    # Delay between API requests\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Save progress every 100 reviews\n",
        "    if i % 100 == 0 and i > 0:\n",
        "        df['claude_cleaned'] = claude_cleaned_reviews\n",
        "        df.to_csv('claude_cleaned_progress.csv', index=False)\n",
        "        print(f\"  Claude progress saved at review {i}\")\n",
        "\n",
        "# Final save\n",
        "df['claude_cleaned'] = claude_cleaned_reviews\n",
        "df.to_csv('claude_cleaned_reviews.csv', index=False)\n",
        "\n",
        "print(\"All reviews cleaned with Claude\")\n",
        "print(\"Saved to 'claude_cleaned_reviews.csv'\")\n",
        "\n",
        "# Download on Colab\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('claude_cleaned_reviews.csv')\n",
        "    print(\"File downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUPeTtOFOxNY"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Clean Noisy Reviews with GPT\n",
        "# Processes all noisy reviews through OpenAI GPT\n",
        "# Includes retry logic and progress saving\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nGPT Cleaning Process\")\n",
        "\n",
        "# Load data with Claude cleaning\n",
        "df = pd.read_csv('claude_cleaned_reviews.csv')\n",
        "\n",
        "# Check if we're resuming from a previous run\n",
        "if 'gpt_cleaned' in df.columns:\n",
        "    gpt_cleaned_reviews = df['gpt_cleaned'].tolist()\n",
        "    # Find where we left off\n",
        "    start_from = 0\n",
        "    for idx, val in enumerate(gpt_cleaned_reviews):\n",
        "        if val == '' or pd.isna(val):\n",
        "            start_from = idx\n",
        "            break\n",
        "        start_from = idx + 1\n",
        "    print(f\"Resuming GPT cleaning from review {start_from}\")\n",
        "else:\n",
        "    gpt_cleaned_reviews = [''] * len(df)\n",
        "    start_from = 0\n",
        "    print(f\"Starting GPT cleaning from review 0\")\n",
        "\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "print(f\"Remaining: {len(df) - start_from}\")\n",
        "\n",
        "# Clean each review with GPT\n",
        "for i in range(start_from, len(df)):\n",
        "    noisy_text = df['noisy_text'].iloc[i]\n",
        "\n",
        "    # Progress update every 25 reviews\n",
        "    if i % 25 == 0:\n",
        "        print(f\"GPT progress: {i}/{len(df)} reviews cleaned...\")\n",
        "\n",
        "    # Retry mechanism for API errors\n",
        "    retry_count = 0\n",
        "    max_retries = 3\n",
        "\n",
        "    while retry_count < max_retries:\n",
        "        try:\n",
        "            cleaned = clean_with_openai(noisy_text)\n",
        "            gpt_cleaned_reviews[i] = cleaned\n",
        "            break  # Success, move to next review\n",
        "\n",
        "        except Exception as e:\n",
        "            error_str = str(e).lower()\n",
        "\n",
        "            # Check for rate limit / overload errors\n",
        "            if \"rate\" in error_str or \"limit\" in error_str or \"429\" in error_str:\n",
        "                retry_count += 1\n",
        "                if retry_count < max_retries:\n",
        "                    print(f\"  GPT API busy at review {i}, waiting 10 seconds... (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(10)\n",
        "                else:\n",
        "                    print(f\"  Skipping review {i} after {max_retries} retries\")\n",
        "                    gpt_cleaned_reviews[i] = noisy_text  # Keep noisy if all retries fail\n",
        "            else:\n",
        "                # Other errors - don't retry\n",
        "                print(f\"  Error at review {i}: {e}\")\n",
        "                gpt_cleaned_reviews[i] = noisy_text\n",
        "                break\n",
        "\n",
        "    # Delay between API requests\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Save progress every 100 reviews\n",
        "    if i % 100 == 0 and i > 0:\n",
        "        df['gpt_cleaned'] = gpt_cleaned_reviews\n",
        "        df.to_csv('gpt_cleaned_progress.csv', index=False)\n",
        "        print(f\"  GPT progress saved at review {i}\")\n",
        "\n",
        "# Final save\n",
        "df['gpt_cleaned'] = gpt_cleaned_reviews\n",
        "df.to_csv('llm_cleaned_reviews.csv', index=False)\n",
        "\n",
        "print(\"All reviews cleaned with GPT\")\n",
        "print(\"Saved to 'llm_cleaned_reviews.csv'\")\n",
        "\n",
        "# Show examples\n",
        "print(\"\\nCleaning Comparison Examples:\")\n",
        "\n",
        "for i in range(2):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"NOISY:   {df['noisy_text'].iloc[i][:100]}...\")\n",
        "    print(f\"CLAUDE:  {df['claude_cleaned'].iloc[i][:100]}...\")\n",
        "    print(f\"GPT:     {df['gpt_cleaned'].iloc[i][:100]}...\")\n",
        "\n",
        "# Download on Colab\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('llm_cleaned_reviews.csv')\n",
        "    print(\"File downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk1_X_jrOxP-"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Load Trained Model\n",
        "# Works on both Colab and Local\n",
        "# Upload model zip on Colab, or use local path\n",
        "# This can be run in a completely new Colab session or on local machine\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nLoad Trained Model\")\n",
        "\n",
        "if IS_COLAB:\n",
        "    # On Colab: Upload the model zip file\n",
        "    print(\"Please upload 'sentiment_model.zip' (if not already present)\")\n",
        "\n",
        "    # Check if model already exists\n",
        "    if not os.path.exists('./sentiment_model'):\n",
        "        from google.colab import files\n",
        "        import zipfile\n",
        "\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # Unzip the model\n",
        "        if 'sentiment_model.zip' in uploaded:\n",
        "            print(\"Extracting model...\")\n",
        "            with zipfile.ZipFile('sentiment_model.zip', 'r') as zip_ref:\n",
        "                zip_ref.extractall('.')\n",
        "            print(\"Model extracted\")\n",
        "        else:\n",
        "            print(\"Error: Please upload 'sentiment_model.zip'\")\n",
        "    else:\n",
        "        print(\"Model already available\")\n",
        "else:\n",
        "    # On Local: Use local path\n",
        "    print(\"Loading model from local directory './sentiment_model'\")\n",
        "    if not os.path.exists('./sentiment_model'):\n",
        "        print(\"Error: Model not found\")\n",
        "        print(\"Please make sure './sentiment_model' directory exists\")\n",
        "        print(\"Or copy the model folder to this directory\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "print(\"Loading model and tokenizer...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./sentiment_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_model\")\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(\"Model loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcvizRTXOxSU"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Evaluation - Predict on All Conditions\n",
        "# Tests model on Clean, Noisy, Claude-Cleaned, and GPT-Cleaned text\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nEvaluation: Predicting on All Conditions\")\n",
        "\n",
        "# Load test data with all versions\n",
        "df = pd.read_csv('llm_cleaned_reviews.csv')\n",
        "print(f\"Loaded {len(df)} test reviews\")\n",
        "\n",
        "def predict_sentiment(texts):\n",
        "    \"\"\"Get model predictions for a list of texts\"\"\"\n",
        "    all_preds = []\n",
        "\n",
        "    # Process in batches for efficiency\n",
        "    batch_size = 32\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "            all_preds.extend(preds.numpy().tolist())\n",
        "\n",
        "    return all_preds\n",
        "\n",
        "# Get predictions for all four conditions\n",
        "print(\"Generating predictions...\")\n",
        "print(\"  1/4: Clean text...\")\n",
        "clean_preds = predict_sentiment(df['text'].tolist())\n",
        "\n",
        "print(\"  2/4: Noisy text...\")\n",
        "noisy_preds = predict_sentiment(df['noisy_text'].tolist())\n",
        "\n",
        "print(\"  3/4: Claude-cleaned text...\")\n",
        "claude_preds = predict_sentiment(df['claude_cleaned'].tolist())\n",
        "\n",
        "print(\"  4/4: GPT-cleaned text...\")\n",
        "gpt_preds = predict_sentiment(df['gpt_cleaned'].tolist())\n",
        "\n",
        "print(\"All predictions complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTwvUBb9OxU7"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Calculate Metrics for All Conditions\n",
        "# Computes accuracy, precision, recall, F1, and confusion matrix\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nMetrics Calculation\")\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, condition_name):\n",
        "    \"\"\"Calculate and display all metrics for a condition\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{condition_name}:\")\n",
        "    print(f\"  Accuracy:  {acc:.1%}\")\n",
        "    print(f\"  Precision: {prec:.1%}\")\n",
        "    print(f\"  Recall:    {rec:.1%}\")\n",
        "    print(f\"  F1-Score:  {f1:.1%}\")\n",
        "    print(f\"  Confusion Matrix:\")\n",
        "    print(f\"    TN={cm[0][0]:4d}  FP={cm[0][1]:4d}\")\n",
        "    print(f\"    FN={cm[1][0]:4d}  TP={cm[1][1]:4d}\")\n",
        "\n",
        "    return {\n",
        "        'condition': condition_name,\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1_score': f1,\n",
        "        'true_neg': cm[0][0],\n",
        "        'false_pos': cm[0][1],\n",
        "        'false_neg': cm[1][0],\n",
        "        'true_pos': cm[1][1]\n",
        "    }\n",
        "\n",
        "# Calculate metrics for all conditions\n",
        "results = []\n",
        "results.append(calculate_metrics(df['label'], clean_preds, \"Clean Text\"))\n",
        "results.append(calculate_metrics(df['label'], noisy_preds, \"Noisy Text\"))\n",
        "results.append(calculate_metrics(df['label'], claude_preds, \"Claude-Cleaned\"))\n",
        "results.append(calculate_metrics(df['label'], gpt_preds, \"GPT-Cleaned\"))\n",
        "\n",
        "# Create summary table\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\nSummary Table:\")\n",
        "print(results_df[['condition', 'accuracy', 'precision', 'recall', 'f1_score']].to_string(index=False))\n",
        "\n",
        "# Calculate impact metrics\n",
        "clean_acc = results_df.loc[0, 'accuracy']\n",
        "noisy_acc = results_df.loc[1, 'accuracy']\n",
        "claude_acc = results_df.loc[2, 'accuracy']\n",
        "gpt_acc = results_df.loc[3, 'accuracy']\n",
        "\n",
        "print(f\"\\nNoise impact: {(clean_acc - noisy_acc):.1%} accuracy drop\")\n",
        "print(f\"Claude recovery: {(claude_acc - noisy_acc):.1%} accuracy recovered\")\n",
        "print(f\"GPT recovery: {(gpt_acc - noisy_acc):.1%} accuracy recovered\")\n",
        "\n",
        "if clean_acc != noisy_acc:\n",
        "    claude_recovery_pct = (claude_acc - noisy_acc) / (clean_acc - noisy_acc) * 100\n",
        "    gpt_recovery_pct = (gpt_acc - noisy_acc) / (clean_acc - noisy_acc) * 100\n",
        "    print(f\"Claude recovery rate: {claude_recovery_pct:.0f}% of lost accuracy recovered\")\n",
        "    print(f\"GPT recovery rate: {gpt_recovery_pct:.0f}% of lost accuracy recovered\")\n",
        "\n",
        "    # Determine which is better\n",
        "    if claude_acc > gpt_acc:\n",
        "        print(f\"\\nClaude performs better: {(claude_acc - gpt_acc):.1%} higher accuracy\")\n",
        "    elif gpt_acc > claude_acc:\n",
        "        print(f\"\\nGPT performs better: {(gpt_acc - claude_acc):.1%} higher accuracy\")\n",
        "    else:\n",
        "        print(f\"\\nClaude and GPT perform equally well\")\n",
        "\n",
        "# Add experiment metadata\n",
        "results_df['noise_config'] = str(NOISE_CONFIG)\n",
        "results_df['test_size'] = len(df)\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('results.csv', index=False)\n",
        "print(\"\\nResults saved to 'results.csv'\")\n",
        "\n",
        "# Download on Colab\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHnpSVDsOxXh"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Visualizations\n",
        "# Generate confusion matrices and accuracy charts comparing all conditions\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nGenerating Visualizations\")\n",
        "\n",
        "# Store predictions\n",
        "all_preds = {\n",
        "    'Clean': clean_preds,\n",
        "    'Noisy': noisy_preds,\n",
        "    'Claude': claude_preds,\n",
        "    'GPT': gpt_preds\n",
        "}\n",
        "\n",
        "# ----- CONFUSION MATRICES -----\n",
        "print(\"1/3: Creating confusion matrices...\")\n",
        "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
        "\n",
        "for idx, (name, preds) in enumerate(all_preds.items()):\n",
        "    cm = confusion_matrix(df['label'], preds)\n",
        "    sns.heatmap(\n",
        "        cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "        xticklabels=['Negative', 'Positive'],\n",
        "        yticklabels=['Negative', 'Positive'],\n",
        "        cbar=False\n",
        "    )\n",
        "    axes[idx].set_title(f'{name}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Predicted', fontsize=10)\n",
        "    axes[idx].set_ylabel('Actual', fontsize=10)\n",
        "\n",
        "plt.suptitle('Confusion Matrices: Clean vs Noisy vs Claude vs GPT',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Saved 'confusion_matrices.png'\")\n",
        "\n",
        "# ----- ACCURACY BAR CHART -----\n",
        "print(\"2/3: Creating accuracy comparison chart...\")\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "conditions = ['Clean\\n(Baseline)', 'Noisy\\n(Problem)', 'Claude\\nCleaned', 'GPT\\nCleaned']\n",
        "accuracies = [clean_acc, noisy_acc, claude_acc, gpt_acc]\n",
        "colors = ['#2E86AB', '#E94F37', '#4DAA57', '#9B59B6']\n",
        "\n",
        "bars = ax.bar(conditions, accuracies, color=colors, width=0.65, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "        f'{acc:.1%}',\n",
        "        ha='center', va='bottom',\n",
        "        fontsize=13, fontweight='bold'\n",
        "    )\n",
        "\n",
        "ax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('Text Condition', fontsize=13, fontweight='bold')\n",
        "ax.set_title('Sentiment Analysis Accuracy: LLM Cleaning Comparison',\n",
        "             fontsize=15, fontweight='bold', pad=20)\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.axhline(y=clean_acc, color='gray', linestyle='--', alpha=0.5, linewidth=1.5, label='Baseline')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Saved 'accuracy_comparison.png'\")\n",
        "\n",
        "# ----- ALL METRICS BAR CHART -----\n",
        "print(\"3/3: Creating all metrics comparison chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "x = np.arange(len(conditions))\n",
        "width = 0.2\n",
        "\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "colors_metrics = ['#2E86AB', '#E94F37', '#4DAA57', '#9B59B6']\n",
        "\n",
        "for i, (metric, label) in enumerate(zip(metrics_to_plot, metric_labels)):\n",
        "    values = results_df[metric].tolist()\n",
        "    offset = (i - 1.5) * width\n",
        "    ax.bar(x + offset, values, width, label=label, color=colors_metrics[i])\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('Text Condition', fontsize=13, fontweight='bold')\n",
        "ax.set_title('All Metrics Comparison: Clean vs Noisy vs Claude vs GPT',\n",
        "             fontsize=15, fontweight='bold', pad=20)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(['Clean', 'Noisy', 'Claude', 'GPT'], fontsize=11)\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.legend(loc='lower right', fontsize=11)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('all_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Saved 'all_metrics_comparison.png'\")\n",
        "\n",
        "print(\"\\nAll visualizations complete\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  confusion_matrices.png\")\n",
        "print(\"  accuracy_comparison.png\")\n",
        "print(\"  all_metrics_comparison.png\")\n",
        "\n",
        "# Download all visualizations on Colab\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('confusion_matrices.png')\n",
        "    files.download('accuracy_comparison.png')\n",
        "    files.download('all_metrics_comparison.png')\n",
        "    print(\"All charts downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR7vbyUuOxaI"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Example Reviews Analysis\n",
        "# Show specific examples where noise affected predictions\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nExample Reviews Analysis\")\n",
        "\n",
        "# Find examples where noise flipped the prediction but LLMs recovered\n",
        "print(\"Finding examples where LLM cleaning recovered from noise...\")\n",
        "\n",
        "examples_found = 0\n",
        "max_examples = 5\n",
        "\n",
        "for i in range(len(df)):\n",
        "    true_label = df['label'].iloc[i]\n",
        "    clean_pred = clean_preds[i]\n",
        "    noisy_pred = noisy_preds[i]\n",
        "    claude_pred = claude_preds[i]\n",
        "    gpt_pred = gpt_preds[i]\n",
        "\n",
        "    # Find cases where clean was correct, noisy was wrong, and at least one LLM recovered\n",
        "    if clean_pred == true_label and noisy_pred != true_label:\n",
        "        if claude_pred == true_label or gpt_pred == true_label:\n",
        "            examples_found += 1\n",
        "\n",
        "            sentiment_name = \"Positive\" if true_label == 1 else \"Negative\"\n",
        "\n",
        "            print(f\"\\nExample {examples_found}: True Sentiment = {sentiment_name}\")\n",
        "            print(f\"CLEAN (Predicted: {['Negative', 'Positive'][clean_pred]}):\")\n",
        "            print(f\"  {df['text'].iloc[i][:180]}...\")\n",
        "            print(f\"NOISY (Predicted: {['Negative', 'Positive'][noisy_pred]}):\")\n",
        "            print(f\"  {df['noisy_text'].iloc[i][:180]}...\")\n",
        "            print(f\"CLAUDE (Predicted: {['Negative', 'Positive'][claude_pred]}):\")\n",
        "            print(f\"  {df['claude_cleaned'].iloc[i][:180]}...\")\n",
        "            print(f\"GPT (Predicted: {['Negative', 'Positive'][gpt_pred]}):\")\n",
        "            print(f\"  {df['gpt_cleaned'].iloc[i][:180]}...\")\n",
        "\n",
        "            if examples_found >= max_examples:\n",
        "                break\n",
        "\n",
        "if examples_found == 0:\n",
        "    print(\"No examples found where LLM cleaning recovered from noise-induced errors\")\n",
        "    print(\"This might indicate:\")\n",
        "    print(\"  - Noise level is too low\")\n",
        "    print(\"  - Model is robust to current noise types\")\n",
        "    print(\"  - Need to add more aggressive noise types\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v6zCuV9OxdA"
      },
      "outputs": [],
      "source": [
        "print(\"\\nAll steps finished successfully\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  sentiment_model/ (directory) - trained on clean data\")\n",
        "print(\"  clean_reviews.csv - original test reviews\")\n",
        "print(\"  noisy_reviews.csv - test reviews with synthetic noise\")\n",
        "print(\"  llm_cleaned_reviews.csv - contains both Claude & GPT cleaned versions\")\n",
        "print(\"  results.csv - performance metrics for all conditions\")\n",
        "print(\"  confusion_matrices.png - visualization\")\n",
        "print(\"  accuracy_comparison.png - visualization\")\n",
        "print(\"  all_metrics_comparison.png - visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4oNysngOxfm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eILGre5hOxie"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}